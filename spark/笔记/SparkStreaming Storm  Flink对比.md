| **对比点**                   | **Storm**                  | **Spark Streaming**                                | **Flink**                                   |
| ---------------------------- | -------------------------- | -------------------------------------------------- | ------------------------------------------- |
| 实时计算模型                 | 纯实时，来一条数据处理一条 | 1、准实时，对一个时间段的RDD数据收集起来，一起处理 | 流失计算和批处理分别采用DataStream和DataSet |
| 实时计算延迟度               | 毫秒级                     | 秒级                                               | 秒级                                        |
| 吞吐量                       | 低                         | 高                                                 | 高                                          |
| 事务机制                     | 支持完善                   | 支持，但不够完善                                   | 支持，但不够完善                            |
| 健壮性/容错性                | ZK、Acker,很好             | CheckPoint，WAL一般                                | CheckPoint一般                              |
| 动态调整并行度               | 支持                       | 不支持                                             | 支持                                        |
| 运行时同时支持流失和离线处理 | 不支持                     | 支持                                               | 支持                                        |
| 成熟度                       | 高                         | 高                                                 | 高                                          |
| 模型                         | native                     | Micro-batching                                     | native                                      |
| API                          | 组合式                     | 声明式                                             | 声明式                                      |



## Spark Streaming



1、Spark Streaming绝对谈不上比Storm、Flink优秀。这两个框架在实时计算领域中，都很优秀，只是擅长的细分场景并不相同。

2、Spark Streaming在吞吐量上要比Storm优秀。

3、Storm在实时延迟度上，比Spark Streaming就好多了，前者是纯实时，后者是准实时。而且，Storm的事务机制、健壮性/容错性、动态调整并行度等特性，都要比Spark Streaming更加优秀。

4、Spark Streaming，有一点是Storm绝对比不上的，就是：它位于Spark整个生态技术栈中，因此Spark Streaming可以和Spark Core、Spark SQL、Spark　Ｇraphx无缝整合，换句话说，我们可以对实时处理出来的中间数据，立即在程序中无缝进行延迟批处理、交互式查询等操作。这个特点大大增强了Spark Streaming的优势和功能。



## 对于Storm来说：

- 1、建议在需要纯实时，不能忍受1秒以上延迟的场景下使用，比如实时计算系统，要求纯实时进行交易和分析时。
- 2、在实时计算的功能中，要求可靠的事务机制和可靠性机制，即数据的处理完全精准，一条也不能多，一条也不能少，也可以考虑使用Storm，但是Spark Streaming也可以保证数据的不丢失。
- 3、如果我们需要考虑针对高峰低峰时间段，动态调整实时计算程序的并行度，以最大限度利用集群资源（通常是在小型公司，集群资源紧张的情况），我们也可以考虑用Storm
  对于Spark Streaming来说：
- 1、不满足上述3点要求的话，我们可以考虑使用Spark Streaming来进行实时计算。
- 2、考虑使用Spark Streaming最主要的一个因素，应该是针对整个项目进行宏观的考虑，即，如果一个项目除了实时计算之外，还包括了离线批处理、交互式查询、图计算和MLIB机器学习等业务功能，而且实时计算中，可能还会牵扯到高延迟批处理、交互式查询等功能，那么就应该首选Spark生态，用Spark Core开发离线批处理，用Spark SQL开发交互式查询，用Spark Streaming开发实时计算，三者可以无缝整合，给系统提供非常高的可扩展性。



## 对于Flink来说：

- 支持高吞吐、低延迟、高性能的流处理
- 支持带有事件时间的窗口（Window）操作
- 支持有状态计算的Exactly-once语义
- 支持高度灵活的窗口（Window）操作，支持基于time、count、session，以及data-driven的窗口操作
- 支持具有Backpressure功能的持续流模型
- 支持基于轻量级分布式快照（Snapshot）实现的容错
- 一个运行时同时支持Batch on Streaming处理和Streaming处理
- Flink在JVM内部实现了自己的内存管理
- 支持迭代计算
- 支持程序自动优化：避免特定情况下Shuffle、排序等昂贵操作，中间结果有必要进行缓存