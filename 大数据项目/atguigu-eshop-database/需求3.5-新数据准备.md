为了分析沉默用户、本周回流用户数、流失用户、最近连续3周活跃用户、最近七天内连续三天活跃用户数，需要准备2019-02-12、2019-02-20日的数据

#### 1 ) 2019-02-12数据准备

- （1）修改日志时间

```
[atguigu@hadoop102 ~]$ dt.sh 2019-02-12
```

- （2）启动集群

```
[atguigu@hadoop102 ~]$ cluster.sh start
```

- （3）生成日志数据

```[atguigu@hadoop102 ~]$ lg.sh```

- （4）将HDFS数据导入到ODS层

```
[atguigu@hadoop102 ~]$ ods_log.sh 2019-02-12
```

- （5）将ODS数据导入到DWD层

```
[atguigu@hadoop102 ~]$ dwd_start_log.sh 2019-02-12

[atguigu@hadoop102 ~]$ dwd_base_log.sh 2019-02-12

[atguigu@hadoop102 ~]$ dwd_event_log.sh 2019-02-12
```

- （6）将DWD数据导入到DWS层

```
[atguigu@hadoop102 ~]$ dws_uv_log.sh 2019-02-12
```

- （7）验证

```
hive (gmall)> select * from dws_uv_detail_day where dt='2019-02-12' limit 2;
```

#### 2）2019-02-20数据准备

- （1）修改日志时间

```
[atguigu@hadoop102 ~]$ dt.sh 2019-02-20
```

- （2）启动集群

```
[atguigu@hadoop102 ~]$ cluster.sh start
```

- （3）生成日志数据

```
[atguigu@hadoop102 ~]$ lg.sh
```

- （4）将HDFS数据导入到ODS层

```
[atguigu@hadoop102 ~]$ ods_log.sh 2019-02-20
```

- （5）将ODS数据导入到DWD层

```
[atguigu@hadoop102 ~]$ dwd_start_log.sh 2019-02-20

[atguigu@hadoop102 ~]$ dwd_base_log.sh 2019-02-20

[atguigu@hadoop102 ~]$ dwd_event_log.sh 2019-02-20
```

- （6）将DWD数据导入到DWS层

```
[atguigu@hadoop102 ~]$ dws_uv_log.sh 2019-02-20
```

- （7）验证

```
hive (gmall)> select * from dws_uv_detail_day where dt='2019-02-20' limit 2;
```

